{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This is a template I created for my own reference in a future project\n",
    "The aim of this project is to extract historical heart rate data at a granular level from fitbit. After that, we will store the granular heart rate data into influxdb cloud for storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import all the neccessary libraries \n",
    "\n",
    "import requests\n",
    "import json\n",
    "import time\n",
    "import pandas as pd\n",
    "import influxdb_client\n",
    "from influxdb_client import InfluxDBClient, Point, WriteOptions\n",
    "from influxdb_client.client.write_api import SYNCHRONOUS\n",
    "from influxdb_client.client import write_api\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### You can follow the tutorial in the youtube video to extract heart rate data to excel file.\n",
    "Link to tutorial: https://www.youtube.com/watch?v=X0RDQWbJw9I\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link to fitbit dev page: https://dev.fitbit.com/apps/details/2389NS\n",
    "\n",
    "Link to Fitbit authorization page:\n",
    "https://dev.fitbit.com/apps/oauthinteractivetutorial?clientEncodedId=2389NS&clientSecret=559b214bae02c7d855e53016c6cb04f9&redirectUri=http://127.0.0.1:8080/&applicationType=SERVER\n",
    "\n",
    "To extract granular heart rate data, we will need to call fitbit api. \n",
    "\n",
    "We will need to access the authorization page to get our UserId and Access_token. \n",
    "\n",
    "The UserId and Access_token is required to call the fitbit api to get our granular heart rate data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Configutations to extract heart rate data from fitbit: \n",
    "\n",
    "# use the UserId provided\n",
    "UserId= \"my_id\"\n",
    "\n",
    "# use the access token provided\n",
    "Access_token=\"my_access_token\"\n",
    "\n",
    "# set a date range we want to get intraday granular heart rate data from \n",
    "\n",
    "start_date = '2018-12-28'\n",
    "end_date = '2019-01-05'\n",
    "\n",
    "# set a start to end time we want to get intraday granular heart rate data from s\n",
    "\n",
    "start_time = '00:00'\n",
    "end_time = '23:59'\n",
    "today_date = '2022-03-11'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test getting heart rate data for 1 day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_request_granular= requests.get(\"https://api.fitbit.com/1/user/\"+UserId+ f\"/activities/heart/date/{start_date}/1d/1min/time/{start_time}/{end_time}.json\", headers = {\"Authorization\": \"Bearer \"+Access_token})\n",
    "\n",
    "# A status_code of 200 means that we have successfully retrieved the heart rate data for 1 day.\n",
    "print(profile_request_granular.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "The fitbit web api will contain an HTTP status code that tells us if the endpoint was successfully executed or not. \n",
    "\n",
    "Link to the status code: https://dev.fitbit.com/build/reference/web-api/troubleshooting-guide/error-handling/\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can only retrieve heart rate data for 1 day at a time. To get heart rate data across a date range, we will have to call the api multiple times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# to store all the heart rate data dataframe\n",
    "empty_df = []\n",
    "\n",
    "\n",
    "while start_date != end_date:\n",
    "    \n",
    "    # check that the start date is incrementing \n",
    "    print(start_date)\n",
    "\n",
    "    # call the api and retrieve our intraday heart rate data \n",
    "    profile_request_granular= requests.get(\"https://api.fitbit.com/1/user/\"+UserId+f\"/activities/heart/date/{start_date}/1d/1min/time/{start_time}/{end_time}.json\", headers = {\"Authorization\": \"Bearer \"+Access_token})\n",
    "    intraday_heart_rate= profile_request_granular.json()['activities-heart-intraday']\n",
    "    \n",
    "    # change the json data to a more familiar pandas dataframe format \n",
    "\n",
    "    heart_rate = pd.DataFrame(intraday_heart_rate['dataset'])\n",
    "    try: \n",
    "        heart_rate['time']= start_date + ' '+ heart_rate['time']\n",
    "        \n",
    "        empty_df.append(heart_rate)\n",
    "\n",
    "        # status code 429 means that we hit the quota s\n",
    "        if profile_request_granular.status_code == 429:\n",
    "            wait = int(profile_request_granular.headers[\"Fitbit-Rate-Limit-Reset\"])+30 \n",
    "            for seconds in tqdm(range(wait)):\n",
    "                time.sleep(1)\n",
    "        \n",
    "        # increment start date by 1 \n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        start_date = datetime.strptime(start_date, date_format)\n",
    "        start_date += timedelta(days=1)\n",
    "        start_date= datetime.strftime(start_date, \"%Y-%m-%d\")\n",
    "\n",
    "\n",
    "    except:\n",
    "        # if error in getting intraday_heart_rate['time], we will just increment the date by 1 regardless            \n",
    "        # increment start date by 1 \n",
    "        date_format = \"%Y-%m-%d\"\n",
    "        start_date = datetime.strptime(start_date, date_format)\n",
    "        start_date += timedelta(days=1)\n",
    "        start_date= datetime.strftime(start_date, \"%Y-%m-%d\")\n",
    "    \n",
    "# concatenate all the data frame together\n",
    "test_rate= pd.concat(empty_df,ignore_index = True)\n",
    "test_rate['time']= pd.to_datetime(test_rate['time'])    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot to visualize our intraday heart rate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sns.set_style(\"darkgrid\")\n",
    "\n",
    "\n",
    "f,ax = plt.subplots(figsize = (16,10))\n",
    "import seaborn as sns\n",
    "sns.lineplot(x = 'time',y = 'value',data = test_rate)\n",
    "# set formatter \n",
    "ax.xaxis.set_major_formatter(\n",
    "    matplotlib.dates.DateFormatter(\"%Y-%m-%d %H:%M\")\n",
    ")\n",
    "plt.xticks(rotation = 45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Influxdb is a time series data platform that is suitable for storing IoT data. \n",
    "\n",
    "Link on more information on time series database:\n",
    "https://www.influxdata.com/time-series-database/\n",
    "\n",
    "We want to push data into influxdb cloud using pandas dataframe. \n",
    "We will batch the data into chunks and push them into the cloud database\n",
    "\n",
    "Tutorial here: https://github.com/influxdata/influxdb-client-python/blob/master/examples/ingest_large_dataframe.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configurations to push the heart rate data into influxdb cloud: \n",
    "\n",
    "# use your own configurations \n",
    "bucket = \"my_bucket\"\n",
    "org = \"my_org\"\n",
    "token = \"my_token\"\n",
    "# Store the URL of your InfluxDB instance\n",
    "url=\"https://ap-southeast-2-1.aws.cloud2.influxdata.com/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "According to the tutorial, we need to set the timestamp column as our index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the timestamp column as index \n",
    "\n",
    "test_heart_rate_to_influx= test_rate.set_index('time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with InfluxDBClient(url=url, token=token, org=org) as client: \n",
    "    \n",
    "    with client.write_api(write_options=WriteOptions(\n",
    "        # batch_size: number of data points to collect in a batch    \n",
    "        batch_size=500,\n",
    "        # flush interval: the numbmer of miliseconds before each batch is written to the cloud \n",
    "        flush_interval=10000,\n",
    "        jitter_interval=2000,\n",
    "        retry_interval=5000)) as write_client:\n",
    "        \n",
    "        write_client.write(bucket=bucket, org=org, record=test_heart_rate_to_influx,data_frame_measurement_name='value')\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1e247a52354105af3e6c4bd48849e82a97d5edc126caee2e15acf47199bbf2fb"
  },
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
